{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer modelo entrenado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo del proyecto es desarrollar un modelo con el mayor grado de exactitud de la compañía móvil Megaline, la cuál no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Se requiere un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra.\n",
    "\n",
    "Se va a trabajar con el dataset `datasets/users_behavior.csv`, el cual contiene la información de los clientes. Este DataSet ya tiene procesados los datos. por lo que se pasará directo a la creación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lectura de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hará la importación de las librerías correspondientes para trabajar en el proyecto y se hará la lectura del dataset.\n",
    "\n",
    "También se estudiará un poco el DataFrame para saber que columnas contiene y cuántos datos hay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del dataset\n",
    "df = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "display(df.head(5))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora sabemos que el DataFrame tiene 5 columnas y la columna `is_ultra` será nuestra columna objetivo, la cuál sólo contiene ceros y unos, que marcan el plan para el mes actual (Ultra - 1, Smart - 0). Esto convierte nuestra tarea en una tarea de <u>Clasificación Binaria</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Segmentación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar el modelo debemos separar el dataset en tres conjuntos: entrenamiento, prueba y validación. Para saber cuántos datos debe contener cada set, tomando en cuenta que no se tiene un conjunto de prueba, se usará una porporción de datos de 3:1:1. Esto quiere decir que el 60% del dataset será para el entrenamiento, 20% para validación y 20% para prueba.\n",
    "\n",
    "Pero, primero debemos separar las características del objetivo en diferentes conjuntos de nuestro dataset principal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>49.0</td>\n",
       "      <td>316.69</td>\n",
       "      <td>46.0</td>\n",
       "      <td>17519.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>73.0</td>\n",
       "      <td>463.74</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21860.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used\n",
       "1202   49.0   316.69      46.0  17519.29\n",
       "911    73.0   463.74      29.0  21860.13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2587    1\n",
       "1583    0\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df con las características\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "display(features.sample(2))\n",
    "\n",
    "# Objetivo\n",
    "target = df['is_ultra']\n",
    "display(target.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que se tienen las características y el objetivo por separado, se hará uso de la función `train_test_split` de la librería de `sklearn`. Esta función sólo puede divir el dataset en 2, por lo que se usará dos veces. Primero se separará el conjunto de entrenamiento y prueba, después se volverá a usar para dividir de nuevo el conjunto de entrenamiento en validación y entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División del dataset en df_train y df_test\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size = 0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda división del dataset\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, target_train, test_size = 0.25, random_state=12345)\n",
    "# Se usa 0.25 porque 0.8*0.25=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrenarán tres modelos: árbol de decisión, bsque aleatorio y regresión logística. De estos se tomará el que mantenga un umbral de exactitud de 0.75 para comprobar la calidad con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Árbol de decisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo se investigará la calidad modificando el hiperparámetro `max_depth` para saber a qué profundidad de árbol es mejor la exactitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth 1 :0.7387247278382582\n",
      "max_depth 2 :0.7573872472783826\n",
      "max_depth 3 :0.7651632970451011\n",
      "max_depth 4 :0.7636080870917574\n",
      "max_depth 5 :0.7589424572317263\n"
     ]
    }
   ],
   "source": [
    "# Se entrena el modelo para diferentes profundidades y se saca su exactitud\n",
    "for depth in range(1,6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    print(\"max_depth\", depth, \":\", end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al probar diferentes profundidades, se observa que la profundidad que más se acerca al umbral que queremos es la profundidad 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Bosque Aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este modelo se modificará el hiperparámetro `n_estimators` para saber cuál es la mejor cantidad de árboles para nuestro modelo. Se evaluarán hasta un máximo de 20 árboles debido a los procesos necesarios de computación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo (n_estimators=1): 0.702954898911353\n",
      "La exactitud del modelo (n_estimators=2): 0.7573872472783826\n",
      "La exactitud del modelo (n_estimators=3): 0.744945567651633\n",
      "La exactitud del modelo (n_estimators=4): 0.7651632970451011\n",
      "La exactitud del modelo (n_estimators=5): 0.7620528771384136\n",
      "La exactitud del modelo (n_estimators=6): 0.7698289269051322\n",
      "La exactitud del modelo (n_estimators=7): 0.7713841368584758\n",
      "La exactitud del modelo (n_estimators=8): 0.7869362363919129\n",
      "La exactitud del modelo (n_estimators=9): 0.7838258164852255\n",
      "La exactitud del modelo (n_estimators=10): 0.7884914463452566\n",
      "La exactitud del modelo (n_estimators=11): 0.7807153965785381\n",
      "La exactitud del modelo (n_estimators=12): 0.7822706065318819\n",
      "La exactitud del modelo (n_estimators=13): 0.7776049766718507\n",
      "La exactitud del modelo (n_estimators=14): 0.7853810264385692\n",
      "La exactitud del modelo (n_estimators=15): 0.7838258164852255\n",
      "La exactitud del modelo (n_estimators=16): 0.7838258164852255\n",
      "La exactitud del modelo (n_estimators=17): 0.7776049766718507\n",
      "La exactitud del modelo (n_estimators=18): 0.7869362363919129\n",
      "La exactitud del modelo (n_estimators=19): 0.7869362363919129\n",
      "La exactitud del modelo (n_estimators=20): 0.7900466562986003\n"
     ]
    }
   ],
   "source": [
    "# Primero inicializamos nuestras variables que contendran el mejor score de la mejor estimación\n",
    "best_score = 0\n",
    "best_est = 0\n",
    "\n",
    "# Se entrena el modelo para diferentes profundidades y se saca su score\n",
    "for est in range (1,21):\n",
    "    model_forest = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model_forest.fit(features_train, target_train)\n",
    "    score = model_forest.score(features_valid, target_valid)\n",
    "    best_score = score\n",
    "    best_est = est    \n",
    "    print('La exactitud del modelo (n_estimators={}): {}'.format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar entre más número de árboles hay, es mejor la exactitud. Sin embargo, nuestro umbral debe ser de 0.75 y el estimador que más se acerca a ese número es `n_estimators` = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este modelo vamos a especificar `solver` como `liblinear` porque es la más general y funciona bien con conjuntos de datos pequeños."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo de Regresión Logística es: 0.7293934681181959\n"
     ]
    }
   ],
   "source": [
    "model_regression = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model_regression.fit(features_train, target_train)\n",
    "score_valid = model_regression.score(features_valid, target_valid)\n",
    "print('La exactitud del modelo de Regresión Logística es:', score_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exactitud no se acerca tanto al umbral que requerimos como los dos modelos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "El mejor modelo para poder probar la calidad con el conjunto de prueba es el bosque aleatorio con un estimador = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo con conjunto de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a evaluar la calidad del conjunto de prueba con el mejor modelo que se encontró: Bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud con el conjunto de prueba es de: 0.7729393468118196\n"
     ]
    }
   ],
   "source": [
    "# Se coloca n_estimators en 3\n",
    "model_test = RandomForestClassifier(random_state=12345, n_estimators=3)\n",
    "model_test.fit(features_train, target_train)\n",
    "score_test = model_test.score(features_test, target_test)\n",
    "print('La exactitud con el conjunto de prueba es de:', score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones:\n",
    "\n",
    "La exactitud es de 0.77, la cuál se acerca al umbral que teníamos. Esta exactitud irá creciendo si se usan más números de árboles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prueba de cordura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta prueba de cordura se ha decidido colocar todas las respuestas con el mismo valor, y verificar su exactitud. Se pondrá 0 para todas las respuestas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud entre el target y las predicciones puestas en 0 es de: 0.693528313627878\n"
     ]
    }
   ],
   "source": [
    "# Se colocan todas las respuestas en 0\n",
    "predictions = pd.Series(0, index=target.index)\n",
    "\n",
    "# Se calcula la exactitud de predictions con el target\n",
    "result = accuracy_score(target, predictions)\n",
    "print('La exactitud entre el target y las predicciones puestas en 0 es de:', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "La exactitud es de 0.69, la cuál si es baja, pero parece aceptable para un modelo cuyas predicciones son todas 0. Esto quiere decir que hay un 69% de probabilidad de acertar que el plan que elegirá el cliente, si colocamos que todos lo clientes quieren un plan Smart.\n",
    "\n",
    "Nuestro modelo tiene una exactitud de 0.77. Esto quiere decir que nuetro modelo tiene una mejor probabilidad de poder predcir el plan que el cliente prefiere, ya sea Smart o Ultra. Nuestro modelo es mucho mejor.\n",
    "\n",
    "Si nuestro modelo estuviera por debajo del 0.69, daría a entender que el modelo es tan malo que sería mejor no hacerlo y colocar que todos los clientes prefieren el plan Smart."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
